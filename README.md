# âœ‚ï¸ PrunerTinyLLaVA: Efficient Multimodal LLM on RTX 4060 laptop

**åœ¨æ¶ˆè´¹çº§æ˜¾å¡ä¸Šè·‘èµ·æ¥çš„é«˜æ•ˆå¤šæ¨¡æ€å¤§æ¨¡å‹ (Efficient MLLM)**

[![Python](https://img.shields.io/badge/Python-3.10%2B-blue)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.4-orange)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-Apache%202.0-green)](./LICENSE)
# PrunerTinyLLaVA

Efficient Multimodal Large Language Model with Learnable Token Pruning  
è¿è¡Œäº RTX 4060 Laptop çš„è½»é‡å¤šæ¨¡æ€æ¨¡å‹

![HybridTokenPruner æ¶æ„](pruner.png)

---

## ğŸš€ Overview

PrunerTinyLLaVA æ˜¯ä¸€ä¸ªé¢å‘æ¶ˆè´¹çº§æ˜¾å¡çš„å¤šæ¨¡æ€ LLM å·¥ç¨‹é¡¹ç›®ã€‚  
ç›®æ ‡æ˜¯åœ¨ **æœ‰é™æ˜¾å­˜ï¼ˆ8GBï¼‰** åœºæ™¯ä¸‹ï¼Œæä¾›å¯è®­ç»ƒã€å¯æ¨ç†çš„é«˜æ•ˆæ¨¡å‹åŸå‹ã€‚

é¡¹ç›®åŒ…å«ä¸‰éƒ¨åˆ†æ ¸å¿ƒç»„ä»¶ï¼š

1. **Vision Encoder:** SigLIP SO400M (patch14, 384px)  
2. **Language Model:** Qwen2.5-0.5B-Instruct  
3. **Hybrid Token Pruner:** å¯å­¦ä¹  Token å‰ªææ¨¡å—ï¼Œç”¨äºå‡å°‘è§†è§‰ token è´Ÿè½½

Pruner çš„ä»»åŠ¡æ˜¯å‹ç¼© SigLIP è¾“å‡ºçš„ 576 ä¸ªè§†è§‰ tokenï¼Œå¹¶ç­›é€‰å‡ºæ¨¡å‹æœ€ä¾èµ–çš„éƒ¨åˆ†ï¼Œä»è€Œé™ä½æ¨ç†æˆæœ¬ã€‚

---

## âœ¨ Features

- **è½»é‡åŒ–æ¨¡å‹æ¶æ„**  
  é€‚åˆ 3060 / 4060 Laptop åœ¨ 6GB VRAM å†…è®­ç»ƒã€‚

- **Hybrid Token Pruner**  
  ç»“åˆ Top-K é€‰æ‹© + å¹³å‡æ± åŒ–å‹ç¼©ï¼Œè§†è§‰ token ä» **576 â†’ 180**ã€‚

- **ä¸¤é˜¶æ®µè®­ç»ƒæµç¨‹**  
  - Stage 1: Projector + Pruner é¢„è®­ç»ƒ  
  - Stage 2: å…¨é‡æŒ‡ä»¤å¾®è°ƒ

- **æ˜¾å­˜å ç”¨ä½**  
  - è®­ç»ƒï¼šçº¦ 5.5â€“6GB  
  - æ¨ç†ï¼šçº¦ 1.5â€“2GB

- **å¯å¤ç°å·¥ç¨‹ç»“æ„**  
  ä»£ç æ¨¡å—åŒ–ï¼Œæ˜“äºä¿®æ”¹å’Œé‡æ–°æ··æ­ã€‚

---

## ğŸ“¦ Project Structure

```text
PrunerTinyLLaVA/
â”œâ”€â”€ data/                     # æ•°æ®é›†
â”‚   â”œâ”€â”€ images/               # COCO / LLaVA å›¾åƒ
â”‚   â””â”€â”€ annotations/          # caption / instruction æ•°æ®
â”‚
â”œâ”€â”€ local_models/             # é¢„è®­ç»ƒæ¨¡å‹ç¼“å­˜ (è‡ªåŠ¨ä¸‹è½½)
â”‚
â”œâ”€â”€ model.py                  # æ¨¡å‹ç»“æ„ (LLM + Projector + Pruner)
â”œâ”€â”€ pruner.py                 # Hybrid Token Pruner æ¨¡å—
â”œâ”€â”€ projector.py              # Vision â†’ LLM Projector
â”œâ”€â”€ dataset.py                # æ•°æ®å¤„ç†
â”‚
â”œâ”€â”€ inference.py              # æ¨ç†è„šæœ¬
â”œâ”€â”€ train_stage1.py           # Stage 1 è®­ç»ƒ
â”œâ”€â”€ train_stage2.py           # Stage 2 è®­ç»ƒ
â”‚
â”œâ”€â”€ requirements.txt          # Python ä¾èµ–
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ ç¯å¢ƒæ­å»º (Environment Setup)
```bash  
git clone https://github.com/your-username/PrunerTinyLLaVA.git
cd PrunerTinyLLaVA

conda create -n pruner-llava python=3.10 -y
conda activate pruner-llava

pip install -r requirements.txt
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹ (Quick Start)
### 1. å¿«é€Ÿæ¨ç†
```bash
python inference.py \
  --image_path "data/coco/images/val2017/000000000139.jpg" \
  --question "è¿™å¼ å›¾ç‰‡é‡Œæœ‰ä»€ä¹ˆï¼Ÿ" \
  --device cuda:0
```

### 2. åˆ†é˜¶æ®µè®­ç»ƒ
```bash
python train_stage1.py \
  --batch_size 1 \
  --gradient_accumulation_steps 8 \
  --output_dir "output_stage1"

python train_stage2.py \
  --batch_size 1 \
  --gradient_accumulation_steps 8 \
  --stage1_ckpt "output_stage1/best_model.pth" \
  --output_dir "output_stage2"
```

---

## ğŸ™ è‡´è°¢ (Acknowledgements)
- æ„Ÿè°¢ LLaVA é¡¹ç›®æä¾›å¤šæ¨¡æ€æ¨¡å‹åŸºç¡€æ¡†æ¶
- æ„Ÿè°¢ Qwen å›¢é˜Ÿå¼€æºè½»é‡åŒ–è¯­è¨€æ¨¡å‹
- æ„Ÿè°¢ SigLIP æä¾›é«˜æ•ˆè§†è§‰å¡”

